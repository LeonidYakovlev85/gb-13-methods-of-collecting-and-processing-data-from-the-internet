# gb-13-methods-of-collecting-and-processing-data-from-the-internet
Домашние задания к курсу "Методы сбора и обработки данных из сети Интернет"
___

## Урок 1. Основы клиент-серверного взаимодействия. Парсинг API

1. Посмотреть документацию к API GitHub, разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.

2. Изучить список открытых API. Найти среди них любое, требующее авторизацию (любого типа). Выполнить запросы к нему, пройдя авторизацию. Ответ сервера записать в файл.  
*В целях соблюдения конфиденциальности я удалил свой токен, но результаты запроса записаны в соответствующий файл*
___

## Урок 2. Парсинг HTML. Beautiful Soup

1. Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайтов Superjob и HH. Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:
    * наименование вакансии;
    * предлагаемую зарплату (отдельно минимальную и максимальную);
    * ссылку на саму вакансию;
    * сайт, откуда собрана вакансия.

 По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas.

 Можно выполнить по желанию один любой вариант или оба при желании и возможности.

### Пояснение к решению:

1. Количество страниц, в соответствии с рекомендацией преподавателя, задаётся через аргумент и равно пяти.
2. Для вывода данных о предполагаемой зарплате условия указаны не в полном объёме. В случае, если не указана "зарплатная вилка" и ни один из "порогов" ("от" или "до"), то значение зарплаты принимается и как минимальное, и как максимальное сразу.
3. К качестве условий выбран город Санкт-Петербург и профессия аналитик Big Data.
___
